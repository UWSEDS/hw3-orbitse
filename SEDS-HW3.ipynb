{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erin Orbits\n",
    "\n",
    "For this homework, you are a data scientist working for Pronto (before the end of their contract with the City of Seattle). Your job is to assist in determining how to do end-of-day adjustments in the number of bikes at stations so that all stations will have enough bikes for the next day of operation (as estimated by the weekday average for the station for the year). Your assistance will help in constructing a plan for each day of the week that specifies how many bikes should be moved from each station and how many bikes must be delievered to each station.\n",
    "\n",
    "Your assignment is to construct plots of the differences between 'from' and 'to' counts for each station by day of the week. Do this as a set of 7 subplots. You should use at least one function to construct your plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "# The following ensures that the plots are in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431</td>\n",
       "      <td>10/13/2014 10:31</td>\n",
       "      <td>10/13/2014 10:48</td>\n",
       "      <td>SEA00298</td>\n",
       "      <td>985.935</td>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "      <td>CBD-06</td>\n",
       "      <td>PS-04</td>\n",
       "      <td>Annual Member</td>\n",
       "      <td>Male</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>432</td>\n",
       "      <td>10/13/2014 10:32</td>\n",
       "      <td>10/13/2014 10:48</td>\n",
       "      <td>SEA00195</td>\n",
       "      <td>926.375</td>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "      <td>CBD-06</td>\n",
       "      <td>PS-04</td>\n",
       "      <td>Annual Member</td>\n",
       "      <td>Male</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433</td>\n",
       "      <td>10/13/2014 10:33</td>\n",
       "      <td>10/13/2014 10:48</td>\n",
       "      <td>SEA00486</td>\n",
       "      <td>883.831</td>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "      <td>CBD-06</td>\n",
       "      <td>PS-04</td>\n",
       "      <td>Annual Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434</td>\n",
       "      <td>10/13/2014 10:34</td>\n",
       "      <td>10/13/2014 10:48</td>\n",
       "      <td>SEA00333</td>\n",
       "      <td>865.937</td>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "      <td>CBD-06</td>\n",
       "      <td>PS-04</td>\n",
       "      <td>Annual Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>1977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435</td>\n",
       "      <td>10/13/2014 10:34</td>\n",
       "      <td>10/13/2014 10:49</td>\n",
       "      <td>SEA00202</td>\n",
       "      <td>923.923</td>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "      <td>CBD-06</td>\n",
       "      <td>PS-04</td>\n",
       "      <td>Annual Member</td>\n",
       "      <td>Male</td>\n",
       "      <td>1971.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id         starttime          stoptime    bikeid  tripduration  \\\n",
       "0      431  10/13/2014 10:31  10/13/2014 10:48  SEA00298       985.935   \n",
       "1      432  10/13/2014 10:32  10/13/2014 10:48  SEA00195       926.375   \n",
       "2      433  10/13/2014 10:33  10/13/2014 10:48  SEA00486       883.831   \n",
       "3      434  10/13/2014 10:34  10/13/2014 10:48  SEA00333       865.937   \n",
       "4      435  10/13/2014 10:34  10/13/2014 10:49  SEA00202       923.923   \n",
       "\n",
       "     from_station_name                                    to_station_name  \\\n",
       "0  2nd Ave & Spring St  Occidental Park / Occidental Ave S & S Washing...   \n",
       "1  2nd Ave & Spring St  Occidental Park / Occidental Ave S & S Washing...   \n",
       "2  2nd Ave & Spring St  Occidental Park / Occidental Ave S & S Washing...   \n",
       "3  2nd Ave & Spring St  Occidental Park / Occidental Ave S & S Washing...   \n",
       "4  2nd Ave & Spring St  Occidental Park / Occidental Ave S & S Washing...   \n",
       "\n",
       "  from_station_id to_station_id       usertype  gender  birthyear  \n",
       "0          CBD-06         PS-04  Annual Member    Male     1960.0  \n",
       "1          CBD-06         PS-04  Annual Member    Male     1970.0  \n",
       "2          CBD-06         PS-04  Annual Member  Female     1988.0  \n",
       "3          CBD-06         PS-04  Annual Member  Female     1977.0  \n",
       "4          CBD-06         PS-04  Annual Member    Male     1971.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"2015_trip_data.csv\")\n",
    "df_original.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, need to create four new columns with the days of the week and dates extracted from the starttime and stoptime for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Not sure whether I should delete the rows with \"Pronto shop\" from the \"original data frame,\" but given the goal and the fact that there were only a few mentions in the data, I decided to delete the rows with the \"Pronto shop.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original = df_original[df_original.from_station_name != \"Pronto shop\"]\n",
    "df_original = df_original[df_original.to_station_name != \"Pronto shop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"day of week\" columns to the original data frame to correspond with the \"To\" and \"From\" groups using the days of the week from the starttime and stoptime columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original[\"from_day_of_week\"] = pd.DatetimeIndex(df_original['starttime']).dayofweek\n",
    "df_original[\"to_day_of_week\"] = pd.DatetimeIndex(df_original['stoptime']).dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the dates columns to correspond with the \"To\" and \"From\" groups using the dates from the starttime and stoptime columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_original[\"from_date\"] = pd.DatetimeIndex(df_original['starttime']).date\n",
    "df_original[\"to_date\"] = pd.DatetimeIndex(df_original['stoptime']).date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check that the four new columns were added to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_original.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second, I counted the number of bikes going to each station and from each station on each day of the week. \n",
    "With groupby you can group by multiple values and use aggregation functions like mean, median, sum, minimum, maximum, standard deviation, or count: <br>\n",
    ">  `<data object>.groupby(<grouping values>).<aggregate>()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to_station_id  to_day_of_week\n",
       "BT-01          0                 791\n",
       "               1                 675\n",
       "               2                 696\n",
       "               3                 791\n",
       "               4                 853\n",
       "Name: to_day_of_week, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a groupby variable that groups stations by day of week and counts the days of the week\n",
    "# example: data.groupby([times.hour, 'gender'])['tripminutes'].mean()\n",
    "toStation_day_count = df_original.groupby([\"to_station_id\", \"to_day_of_week\"])[\"to_day_of_week\"].count()\n",
    "toStation_day_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from_station_id  from_day_of_week\n",
       "BT-01            0                   806\n",
       "                 1                   724\n",
       "                 2                   679\n",
       "                 3                   801\n",
       "                 4                   921\n",
       "Name: from_day_of_week, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromStation_day_count = df_original.groupby([\"from_station_id\", \"from_day_of_week\"])[\"from_day_of_week\"].count()\n",
    "fromStation_day_count.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to count the number of weekdays, but couldn't figure it out... Things more or less went off the rails at this point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20404.571428571428"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy.unique(array, return_index=False, return_inverse=False, return_counts=False) \n",
    "# Returns sorted unique elements of an array w/ 3 optional outputs in addition to the unique elements: \n",
    "# the indices of the input array that give the unique values, the indices of the unique array that \n",
    "# reconstruct the input array, and the number of times each unique value comes up in the input array.\n",
    "from_x = df_original.groupby([\"from_date\", \"from_day_of_week\"])[\"from_day_of_week\"].count()\n",
    "from_x_index = from_x.index\n",
    "from_x_index[:][:]\n",
    "np.unique(df_original[\"from_date\"])\n",
    "(df_original[\"from_date\"].count())/7\n",
    "# num_from_weekdays = np.unique(df_original[\"from_day_of_week\"], return_counts=True)\n",
    "# (array([0, 1, 2, 3, 4, 5, 6]),\n",
    "#  array([21262, 20462, 20746, 21502, 21095, 20358, 17407], dtype=int64))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_to_weekdays = np.unique(df_original[\"to_day_of_week\"], return_counts=True)\n",
    "# (array([0, 1, 2, 3, 4, 5, 6]),\n",
    "#  array([21258, 20478, 20729, 21496, 21069, 20348, 17454], dtype=int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With value_counts, the Pandas method takes a series object and returns object containing counts of unique values: <br>\n",
    "> series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to_date     to_day_of_week  to_station_id\n",
       "2014-10-13  0               BT-01             6\n",
       "                            BT-03            11\n",
       "                            BT-04             3\n",
       "                            BT-05             6\n",
       "                            CBD-03           16\n",
       "Name: to_date, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "# pd.value_counts(to_station_count[\"day_of_week\"], sort=True)\n",
    "# to_mean = df_original.groupby([\"day_of_week\", \"to_station_id\"])[\"day_of_week\"].mean()\n",
    "to_station = df_original.groupby([\"to_day_of_week\", \"to_station_id\"])[\"to_day_of_week\"]\n",
    "to_counts = df_original[\"to_station_id\"].value_counts(normalize=True, sort=True, dropna=True)\n",
    "to_counts.head(10)\n",
    "np.unique(df_original[\"to_station_id\"])\n",
    "per_day_station_count = df_original.groupby([\"to_date\", \"to_day_of_week\", \"to_station_id\"])[\"to_date\"].count()\n",
    "per_day_station_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,      9,\n",
       "            ...\n",
       "            142836, 142837, 142838, 142839, 142840, 142841, 142842, 142843,\n",
       "            142844, 142845],\n",
       "           dtype='int64', length=21258)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Scipy Stats #####\n",
    "# scipy.stats.binned_statistic(x, values, statistic='mean', bins=10)\n",
    "# scipy.stats.binned_statistic_2d(x, y, values, statistic='mean', bins=10, range=None, expand_binnumbers=False)\n",
    "# scipy.stats.binned_statistic_2d([0,1,2,3,4,5,6], \n",
    "#                                ['BT-01', 'BT-03', 'BT-04', 'BT-05', 'CBD-03', 'CBD-04', 'CBD-05'])\n",
    "monday_df = df_original[df_original[\"to_day_of_week\"] ==0] # 21258 rows × 16 columns\n",
    "monday_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 7, 54)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_index = to_station_count.index  # names=['stop_date', 'day_of_stop_week', 'to_station_id'])\n",
    "to_index.levshape # (365, 7, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to compute the average value across the days for each station. The groupby produced a MultiIndex. \n",
    "# So, further operations on the result must take this into account.\n",
    "# Example:  h_index = groupby_day_from.index\n",
    "#           h_index.levshape  # Size of the components of the MultiIndex\n",
    "\n",
    "# from_station_count is a Series pandas object with a multilevel index (so it has no columns)\n",
    "from_station_count = df_original.groupby([\"from_date\", \"from_day_of_week\", \"from_station_id\"])[\"from_day_of_week\"].count()\n",
    "from_index = from_station_count.index\n",
    "from_index.levshape # (365, 7, 54)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_date  day_of_start_week  from_station_id\n",
       "2014-10-13  0                  BT-01              10\n",
       "                               BT-03               6\n",
       "                               BT-04              13\n",
       "                               BT-05               1\n",
       "                               CBD-03             14\n",
       "                               CBD-05             18\n",
       "                               CBD-06             26\n",
       "                               CBD-07              6\n",
       "                               CBD-13              8\n",
       "                               CH-01               3\n",
       "                               CH-02              21\n",
       "                               CH-03               1\n",
       "                               CH-05              11\n",
       "                               CH-06               6\n",
       "                               CH-07               7\n",
       "                               CH-08              12\n",
       "                               CH-09               5\n",
       "                               CH-12               2\n",
       "                               CH-15               5\n",
       "                               DPD-01              4\n",
       "                               DPD-03              4\n",
       "                               EL-01               2\n",
       "                               EL-03               3\n",
       "                               EL-05               2\n",
       "                               FH-01               6\n",
       "                               FH-04               4\n",
       "                               ID-04              10\n",
       "                               PS-04              71\n",
       "                               PS-05              11\n",
       "                               SLU-01             12\n",
       "                                                  ..\n",
       "2015-10-12  0                  DPD-01              4\n",
       "                               DPD-03              2\n",
       "                               EL-01               3\n",
       "                               EL-03              10\n",
       "                               EL-05               8\n",
       "                               FH-01               4\n",
       "                               FH-04              10\n",
       "                               PS-04               5\n",
       "                               PS-05               5\n",
       "                               SLU-01             16\n",
       "                               SLU-02             11\n",
       "                               SLU-04              7\n",
       "                               SLU-07             11\n",
       "                               SLU-15             15\n",
       "                               SLU-16              4\n",
       "                               SLU-17              4\n",
       "                               SLU-18              1\n",
       "                               SLU-19             10\n",
       "                               SLU-20             13\n",
       "                               SLU-21              8\n",
       "                               UD-01               4\n",
       "                               UD-02               3\n",
       "                               UD-04               5\n",
       "                               UD-07               5\n",
       "                               UW-02               2\n",
       "                               UW-04               5\n",
       "                               UW-06               2\n",
       "                               UW-07               3\n",
       "                               WF-01               9\n",
       "                               WF-04               4\n",
       "Name: day_of_start_week, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_means = from_station_count.groupby(level=[0,1,2]).mean() # same as from_station_groupby values\n",
    "from_station_count.index.levels\n",
    "from_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList([[2014-10-13, 2014-10-14, 2014-10-15, 2014-10-16, 2014-10-17, 2014-10-18, 2014-10-19, 2014-10-20, 2014-10-21, 2014-10-22, 2014-10-23, 2014-10-24, 2014-10-25, 2014-10-26, 2014-10-27, 2014-10-28, 2014-10-29, 2014-10-30, 2014-10-31, 2014-11-01, 2014-11-02, 2014-11-03, 2014-11-04, 2014-11-05, 2014-11-06, 2014-11-07, 2014-11-08, 2014-11-09, 2014-11-10, 2014-11-11, 2014-11-12, 2014-11-13, 2014-11-14, 2014-11-15, 2014-11-16, 2014-11-17, 2014-11-18, 2014-11-19, 2014-11-20, 2014-11-21, 2014-11-22, 2014-11-23, 2014-11-24, 2014-11-25, 2014-11-26, 2014-11-27, 2014-11-28, 2014-11-29, 2014-11-30, 2014-12-01, 2014-12-02, 2014-12-03, 2014-12-04, 2014-12-05, 2014-12-06, 2014-12-07, 2014-12-08, 2014-12-09, 2014-12-10, 2014-12-11, 2014-12-12, 2014-12-13, 2014-12-14, 2014-12-15, 2014-12-16, 2014-12-17, 2014-12-18, 2014-12-19, 2014-12-20, 2014-12-21, 2014-12-22, 2014-12-23, 2014-12-24, 2014-12-25, 2014-12-26, 2014-12-27, 2014-12-28, 2014-12-29, 2014-12-30, 2014-12-31, 2015-01-01, 2015-01-02, 2015-01-03, 2015-01-04, 2015-01-05, 2015-01-06, 2015-01-07, 2015-01-08, 2015-01-09, 2015-01-10, 2015-01-11, 2015-01-12, 2015-01-13, 2015-01-14, 2015-01-15, 2015-01-16, 2015-01-17, 2015-01-18, 2015-01-19, 2015-01-20, ...], [0, 1, 2, 3, 4, 5, 6], ['BT-01', 'BT-03', 'BT-04', 'BT-05', 'CBD-03', 'CBD-04', 'CBD-05', 'CBD-06', 'CBD-07', 'CBD-13', 'CD-01', 'CH-01', 'CH-02', 'CH-03', 'CH-05', 'CH-06', 'CH-07', 'CH-08', 'CH-09', 'CH-12', 'CH-15', 'DPD-01', 'DPD-03', 'EL-01', 'EL-03', 'EL-05', 'FH-01', 'FH-04', 'ID-04', 'PS-04', 'PS-05', 'SLU-01', 'SLU-02', 'SLU-04', 'SLU-07', 'SLU-15', 'SLU-16', 'SLU-17', 'SLU-18', 'SLU-19', 'SLU-20', 'SLU-21', 'UD-01', 'UD-02', 'UD-04', 'UD-07', 'UW-01', 'UW-02', 'UW-04', 'UW-06', 'UW-07', 'UW-10', 'WF-01', 'WF-04']])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "# group_df = {\"day_of_week\": to_station_groupby[\"day_of_week\"], \"station_id\":to_station_groupby[\"to_station_id\"]}\n",
    "df_counts = pd.DataFrame({'From': from_station_count.sort_index(), 'To': to_station_count.sort_index()})\n",
    "df_counts.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counts.index.levshape # get length of indices\n",
    "df_counts.index.names # gives names of indices, initially set to ['day_of_week', 'from_station_id']\n",
    "df_counts.index = df_counts.rename(index=str, columns={\"from_day_of_week\": \"from_day_of_week\", \"from_station_id\": \"station\"})\n",
    "df_counts.head(10) # not sure why this didn't change the names of the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counts.index.levels[0] # get days of week index Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')\n",
    "df_counts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counts.index.levels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the Delta column to the df_counts data frame to calculate the difference between the bikes going to stations and the bikes leaving from stations each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delta column gives # bikes at station at end of day, Delta = To - From \n",
    "df_counts[\"Delta\"] = df_counts['To'] - df_counts['From']\n",
    "df_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counts.index\n",
    "len(df_counts.index)\n",
    "len(df_counts.index.levels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting two variables as a bar chart\n",
    "\"\"\"\n",
    "n_groups = len(df_counts.index.levels[1])\n",
    "index = np.arange(n_groups)  # The \"raw\" x-axis of the bar plot\n",
    "fig = plt.figure(figsize=(16, 8))  # Controls global properties of the bar plot\n",
    "\n",
    "bar_width = 0.35  # Width of the bars\n",
    "opacity = 0.6  # How transparent the bars are\n",
    "rects1 = plt.bar(index, df_counts.From, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='From')\n",
    "rects2 = plt.bar(index + bar_width, df_counts.To, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='To')\n",
    "plt.xticks(index + bar_width / 2, df_counts.index)\n",
    "_, labels = plt.xticks()  # Get the new labels of the plot\n",
    "plt.setp(labels, rotation=90)  # Rotate labels to make them readable\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Station')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Station Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bar1(df, column, opts):\n",
    "    \"\"\"\n",
    "    Does a bar plot for a single column.\n",
    "    :param pd.DataFrame df:\n",
    "    :param str column: name of the column to plot\n",
    "    :param dict opts: key is plot attribute\n",
    "    \"\"\"\n",
    "    n_groups = len(df.index)\n",
    "    index = np.arange(n_groups)  # The \"raw\" x-axis of the bar plot\n",
    "    rects1 = plt.bar(index, df[column])\n",
    "    if 'xlabel' in opts:\n",
    "      plt.xlabel(opts['xlabel'])\n",
    "    else:\n",
    "      labels = \" \"\n",
    "    if 'ylabel' in opts:\n",
    "      plt.ylabel(opts['ylabel'])\n",
    "      plt.legend(opts['ylabel'])\n",
    "    if ('xticks' and 'xticks') in opts:\n",
    "      plt.xticks(index, df.index)  # Convert \"raw\" x-axis into labels\n",
    "      _, labels = plt.xticks()  # Get the new labels of the plot\n",
    "      plt.setp(labels, rotation=90)  # Rotate labels to make them readable\n",
    "    else:\n",
    "      labels = ['' for x in df.index]\n",
    "      plt.xticks(index, labels)   \n",
    "    if 'ylim' in opts:\n",
    "      plt.ylim(opts['ylim'])\n",
    "    if 'title' in opts:\n",
    "      plt.title(opts['title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotNbar(df, columns, opts):\n",
    "    \"\"\"\n",
    "    Does a bar plot for a single column.\n",
    "    :param pd.DataFrame df:\n",
    "    :param list-of-str columns: names of the column to plot\n",
    "    :param dict opts: key is plot attribute\n",
    "    \"\"\"\n",
    "    num_columns = len(columns)\n",
    "    local_opts = dict(opts)  # Make a deep copy of the object\n",
    "    idx = 0\n",
    "    for column in columns:\n",
    "        idx += 1\n",
    "        local_opts['xticks'] = False\n",
    "        local_opts['xlabel'] = ''\n",
    "        if idx == num_columns:\n",
    "          local_opts['xticks'] = True\n",
    "          local_opts['xlabel'] = opts['xlabel']\n",
    "        plt.subplot(num_columns, 1, idx)\n",
    "        # calls plot_bar1 to plot each column\n",
    "        plot_bar1(df, column, local_opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))  # Controls global properties of the bar plot\n",
    "opts = {'title': 'Station Counts','xlabel': 'Stations', 'ylabel': 'Daily Counts', 'ylim': [0, 1500]}\n",
    "plotNbar(df_counts, ['To', 'From'], opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### Indexing and Selecting Data With Pandas ######\n",
    "# .iloc[row,column]\n",
    "# Select all rows by index label, \n",
    "# Example: Select all rows with index label \"Arizona\"\n",
    "#  df.loc[:'Arizona']\n",
    "# .ix is the combination of both .loc and .iloc. Integers are first considered labels, \n",
    "# but if not found, falls back on positional indexing\n",
    "Monday = df_counts.ix[0]\n",
    "Tuesday = df_counts.ix[1]\n",
    "Tuesday.head(10)\n",
    "type(Monday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))  # Controls global properties of the bar plot\n",
    "opts = {'title': 'Station Counts','xlabel': 'Stations', 'ylabel': 'Daily Counts', 'ylim': [-600, 400]}\n",
    "plotNbar(Monday,[\"Delta\"], opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotN(df, groups, columns, opts):\n",
    "    \"\"\"\n",
    "    Constructs a plot for each group, each plot is constructed by calling plotNbar to draw a bar plot for a each column.\n",
    "    :param pd.DataFrame df:\n",
    "    :param df index groups: index levels for each plot\n",
    "    :param list-of-str columns: names of the column to plot\n",
    "    :param dict opts: key is plot attribute\n",
    "    \"\"\"\n",
    "    num_groups = len(groups)\n",
    "    idx = 0\n",
    "    for group in groups:\n",
    "        columns = df.ix[idx]\n",
    "        idx += 1\n",
    "        plotNbar(df, columns, opts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotN(df_counts, df_counts.index.levels[0], df_counts[,0:1], opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_counts.index.levels[0][1]\n",
    "df_counts.index.labels[0][0]\n",
    "gb = df_counts.groupby(level=0)\n",
    "gb.groups[0]\n",
    "df_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_counts.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = (\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\n",
    "for i in len(days):\n",
    "    days[i] = df_counts.groupby(level=[i])\n",
    "    i += 1\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Monday = df_counts.index.levels[0][0]\n",
    "df_counts.xs(0, level=0, drop_level=False)\n",
    "df_counts.xs(1, level=0, drop_level=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "g = seaborn.FacetGrid(data=df_counts, col=df_counts.index.levels[0], col_wrap)\n",
    "g.map(seaborn.distplot, \"Delta\")\n",
    "seaborn.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
